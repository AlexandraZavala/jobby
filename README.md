# Sistema de Scraping y Vectorizaci√≥n de Empleos

Este sistema automatiza la extracci√≥n de empleos de la plataforma PUCP-CSM, los formatea y los almacena en un vector store para b√∫squedas sem√°nticas.

## üöÄ Instalaci√≥n

1. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

2. **Configurar variables de entorno:**
Crea un archivo `.env` con:
```env
# Credenciales para el scraping
EMAIL=tu_email@ejemplo.com
PASSWORD=tu_password

# API Key de OpenAI para embeddings
OPENAI_API_KEY=tu_openai_api_key_aqui
```

## üìÅ Estructura del Proyecto

- `scrap_all.py` - Script principal de scraping y formateo
- `main.py` - Pipeline completo (scraping + vectorizaci√≥n)
- `format_jobs_for_chatbot.py` - Formateo independiente (opcional)
- `jobs_for_chatbot.json` - Empleos formateados
- `chroma_db/` - Vector store persistido

## üéØ Uso

### Opci√≥n 1: Pipeline Completo (Recomendado)
```bash
python main.py
```

Este comando ejecuta:
1. ‚úÖ Scraping de empleos
2. ‚úÖ Formateo de datos
3. ‚úÖ Creaci√≥n de documentos LangChain
4. ‚úÖ Divisi√≥n en chunks
5. ‚úÖ Vectorizaci√≥n con Chroma

### Opci√≥n 2: Solo Scraping y Formateo
```bash
python scrap_all.py
```

### Opci√≥n 3: Solo Formateo (si ya tienes datos)
```bash
python format_jobs_for_chatbot.py
```

## üìä Archivos Generados

- `jobs_raw.json` - Datos crudos del scraping
- `detalles_empleos.json` - Detalles completos de cada empleo
- `jobs_for_chatbot.json` - Empleos formateados para chatbot
- `chroma_db/` - Vector store para b√∫squedas sem√°nticas

## üîç Uso del Vector Store

Una vez creado, puedes usar el vector store para b√∫squedas:

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# Cargar vector store
embeddings = OpenAIEmbeddings()
vector_store = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings
)

# Buscar empleos similares
results = vector_store.similarity_search("desarrollador python", k=5)
for doc in results:
    print(f"T√≠tulo: {doc.metadata['title']}")
    print(f"Empresa: {doc.metadata['company']}")
    print("---")
```

## ‚öôÔ∏è Configuraci√≥n

### Chunks de Texto
En `main.py` puedes ajustar:
- `chunk_size=1000` - Tama√±o de cada chunk
- `chunk_overlap=200` - Superposici√≥n entre chunks

### Embeddings
El sistema usa OpenAI embeddings por defecto. Puedes cambiar a otros proveedores modificando la funci√≥n `crear_vector_store()`.

## üõ†Ô∏è Soluci√≥n de Problemas

### Error de API Key
```
‚ùå Error creando vector store: Invalid API key
```
**Soluci√≥n:** Verifica que tu `OPENAI_API_KEY` est√© configurada correctamente.

### Error de Credenciales
```
‚ùå Error: Las variables EMAIL y PASSWORD deben estar definidas
```
**Soluci√≥n:** Verifica tu archivo `.env` con las credenciales correctas.

### Error de Dependencias
```
ModuleNotFoundError: No module named 'langchain'
```
**Soluci√≥n:** Ejecuta `pip install -r requirements.txt`

## üìà Estad√≠sticas

El sistema genera estad√≠sticas autom√°ticamente:
- N√∫mero de empleos procesados
- Empresas √∫nicas
- Ubicaciones √∫nicas
- Chunks generados

## üîÑ Actualizaci√≥n

Para actualizar los datos:
1. Ejecuta `python main.py` nuevamente
2. El vector store se sobrescribir√° con datos frescos

## üìù Notas

- El scraping puede tomar varios minutos dependiendo del n√∫mero de empleos
- Aseg√∫rate de tener una conexi√≥n estable a internet
- El vector store se guarda localmente en `./chroma_db`
- Los datos originales se preservan en los archivos JSON 